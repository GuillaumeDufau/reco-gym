{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD-based Agent with LogReg on Bandit Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up until now, we have primarily focused on:\n",
    "- The differences between organic and bandit feedback, and how to properly exploit these signals for model evaluation\n",
    "- Building a model either entirely off of either organic, or bandit feedback\n",
    "- Feature engineering methods in combination with Logistic Regression to properly predict clicks\n",
    "\n",
    "However, we haven't yet looked into combining the organic and the bandit signal to get the best of both worlds.\n",
    "In this notebook, we show a simple example that combines an embedding-based approach (SVD) on the organic signal, with a simple Logistic Regression-based model that predicts whether a given user will interact with a recommendation, should we show it.\n",
    "In conclusion, we show that properly combining these different types of feedback yields a significant gain in model accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.random.mtrand import RandomState\n",
    "from recogym import Configuration\n",
    "from recogym.agents import Agent\n",
    "from scipy.special import logsumexp\n",
    "import pandas as pd\n",
    "from scipy.stats.distributions import beta\n",
    "from copy import deepcopy\n",
    "from recogym.agents import OrganicUserEventCounterAgent, organic_user_count_args\n",
    "\n",
    "from recogym.envs.observation import Observation\n",
    "from recogym.agents import RandomAgent, random_args\n",
    "from recogym import verify_agents, verify_agents_IPS\n",
    "from recogym.evaluate_agent import plot_verify_agents, verify_agents_recall_at_k\n",
    "\n",
    "import pylab\n",
    "\n",
    "# from Keras\n",
    "def to_categorical(y, num_classes=None, dtype='float32'):\n",
    "  y = np.array(y, dtype='int')\n",
    "  input_shape = y.shape\n",
    "  if input_shape and input_shape[-1] == 1 and len(input_shape) > 1:\n",
    "    input_shape = tuple(input_shape[:-1])\n",
    "  y = y.ravel()\n",
    "  if not num_classes:\n",
    "    num_classes = np.max(y) + 1\n",
    "  n = y.shape[0]\n",
    "  categorical = np.zeros((n, num_classes), dtype=dtype)\n",
    "  categorical[np.arange(n), y] = 1\n",
    "  output_shape = input_shape + (num_classes,)\n",
    "  categorical = np.reshape(categorical, output_shape)\n",
    "  return categorical\n",
    "\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "# env_0_args is a dictionary of default parameters (i.e. number of products)\n",
    "from recogym import env_1_args, Configuration\n",
    "\n",
    "# Set style for pretty plots\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "P = 16 # Number of Products\n",
    "U = 5000 # Number of Users\n",
    "\n",
    "# You can overwrite environment arguments here:\n",
    "env_1_args['random_seed'] = 42\n",
    "env_1_args['num_products']= P\n",
    "env_1_args['phi_var']=0.0\n",
    "env_1_args['number_of_flips']=8\n",
    "env_1_args['sigma_mu_organic'] = 0.0\n",
    "env_1_args['sigma_omega']=0\n",
    "#env_1_args['normalize_beta']=True\n",
    "# Initialize the gym for the first time by calling .make() and .init_gym()\n",
    "env = gym.make('reco-gym-v1')\n",
    "env.init_gym(env_1_args)\n",
    "\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>c</th>\n",
       "      <th>ps</th>\n",
       "      <th>ps-a</th>\n",
       "      <th>t</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>organic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>organic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>organic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>[0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.062...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bandit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>[0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.062...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bandit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>[0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.062...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bandit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>[0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.062...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bandit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>organic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>[0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.062...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bandit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>[0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.062...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bandit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>[0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.062...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bandit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>[0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.062...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bandit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>[0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.062...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bandit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>[0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.062...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bandit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>[0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.062...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bandit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>[0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.062...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bandit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>[0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.062...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bandit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>[0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.062...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bandit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>[0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.062...</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bandit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>[0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.062...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bandit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       a    c      ps                                               ps-a   t  \\\n",
       "0    NaN  NaN     NaN                                               None   0   \n",
       "1    NaN  NaN     NaN                                               None   1   \n",
       "2    NaN  NaN     NaN                                               None   2   \n",
       "3   10.0  0.0  0.0625  [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.062...   3   \n",
       "4   11.0  0.0  0.0625  [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.062...   4   \n",
       "5    6.0  0.0  0.0625  [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.062...   5   \n",
       "6   13.0  0.0  0.0625  [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.062...   6   \n",
       "7    NaN  NaN     NaN                                               None   0   \n",
       "8    3.0  0.0  0.0625  [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.062...   1   \n",
       "9    7.0  0.0  0.0625  [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.062...   2   \n",
       "10   6.0  0.0  0.0625  [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.062...   3   \n",
       "11   0.0  0.0  0.0625  [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.062...   4   \n",
       "12   0.0  0.0  0.0625  [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.062...   5   \n",
       "13   2.0  0.0  0.0625  [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.062...   6   \n",
       "14   5.0  0.0  0.0625  [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.062...   7   \n",
       "15   1.0  0.0  0.0625  [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.062...   8   \n",
       "16   6.0  0.0  0.0625  [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.062...   9   \n",
       "17   3.0  0.0  0.0625  [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.062...  10   \n",
       "18  15.0  0.0  0.0625  [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.062...  11   \n",
       "19   9.0  0.0  0.0625  [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.062...  12   \n",
       "\n",
       "    u     v        z  \n",
       "0   0  13.0  organic  \n",
       "1   0   3.0  organic  \n",
       "2   0   9.0  organic  \n",
       "3   0   NaN   bandit  \n",
       "4   0   NaN   bandit  \n",
       "5   0   NaN   bandit  \n",
       "6   0   NaN   bandit  \n",
       "7   1  11.0  organic  \n",
       "8   1   NaN   bandit  \n",
       "9   1   NaN   bandit  \n",
       "10  1   NaN   bandit  \n",
       "11  1   NaN   bandit  \n",
       "12  1   NaN   bandit  \n",
       "13  1   NaN   bandit  \n",
       "14  1   NaN   bandit  \n",
       "15  1   NaN   bandit  \n",
       "16  1   NaN   bandit  \n",
       "17  1   NaN   bandit  \n",
       "18  1   NaN   bandit  \n",
       "19  1   NaN   bandit  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate RecSys logs for U users\n",
    "reco_log = env.generate_logs(U)\n",
    "reco_log.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The critical part of our agent is a Logistic Regression model, that predicts whether a user will click a given recommendation, based on some features.\n",
    "In what follows, we present an overview of these simple features.\n",
    "\n",
    "- The first `K` features are the latent components representing the user state. As proposed in the well-known SVD++ approach and aligned with the previous notebooks, we decompose the item co-count matrix and represent a user with the average embedding of the items in her history.\n",
    "- Following this, we embed the specific item we want to recommend as a one-hot-encoded sparse vector of length `P`.\n",
    "- In order to further exploit the organic signal: we include a count of organic views for the given item in the training set, and the result of the dot-product between the user- and item-embedding.\n",
    "\n",
    "As discussed previously, we need cross-interaction between the user- and item-features to ensure a personalised approach.\n",
    "With this in mind, we take the Kronecker-product between the first `K` and last `P+2` features in order to obtain our final `KP+2` features.\n",
    "\n",
    "We make our agent greedy, i.e. it will always take the action it deems to have the highest probability of generating a click, without any exploratory behaviour for lesser actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def create_embeddings(reco_log, U, P, K = 5):\n",
    "    organic_reco_log = reco_log[reco_log['z']=='organic']\n",
    "    counts = np.zeros((U,P))\n",
    "\n",
    "    for u in range(U):\n",
    "        counts[u,:] = to_categorical(np.array(organic_reco_log[organic_reco_log['u']==u].v,dtype=int),P).sum(0)\n",
    "\n",
    "    counts_above_zero = 1.*(counts>0) # above zero counts only\n",
    "    co_counts = np.matmul(counts_above_zero.T,counts_above_zero)\n",
    "    \n",
    "    w , v = np.linalg.eig(co_counts)\n",
    "    idx = np.argsort(w)[::-1] \n",
    "    v = np.real(v[:,idx])\n",
    "    w = np.real(w[idx])\n",
    "\n",
    "    wdash = np.zeros_like(w)\n",
    "\n",
    "    wdash[0:K] = w[0:K]\n",
    "    embeddings = np.matmul(v,np.sqrt(np.diag(wdash)))[:,0:K] # keep the non-zero components\n",
    "    return embeddings\n",
    "\n",
    "class SVDLogRegAgent(Agent):\n",
    "    def __init__(self, config, reco_log, U = U, P = P, K = 5, greedy = False):\n",
    "        super(SVDLogRegAgent, self).__init__(config)\n",
    "        self.rng = RandomState(self.config.random_seed)\n",
    "        self.organic_views = np.zeros(self.config.num_products)\n",
    "        assert(P >= K)\n",
    "        assert(reco_log.v.max() < P)\n",
    "        self.K = K\n",
    "        self.history_length = 0\n",
    "        self.greedy = greedy\n",
    "        self.item_popularities = defaultdict(int)\n",
    "        self.train(reco_log, U, P)\n",
    "        \n",
    "    def train(self, reco_log, U, P):\n",
    "        # Generate item embeddings by SVD on item co-count matrix\n",
    "        self.embeddings = create_embeddings(reco_log, U, P, self.K)\n",
    "        \n",
    "        # Compute item popularities\n",
    "        for row in reco_log.loc[reco_log['z'] == 'organic'].itertuples():\n",
    "            self.item_popularities[int(row.v)] += 1\n",
    "        \n",
    "        # TODO - Not entirely correct to train embeddings on future data here... Do we care?\n",
    "        # Generate feature-matrix X to train on\n",
    "        X = []\n",
    "        y = []\n",
    "        uid = 0\n",
    "        uemb = np.zeros(self.K)\n",
    "        ucnt = 0\n",
    "        for row in reco_log.itertuples():\n",
    "            # Do we have a new user?\n",
    "            if row.u != uid:\n",
    "                # Reset the embedding\n",
    "                uid = row.u\n",
    "                uemb = np.zeros(self.K)\n",
    "                ucnt = 0\n",
    "            # Is this an organic event?\n",
    "            if row.z == 'organic':\n",
    "                # Update the user embedding\n",
    "                uemb += self.embeddings[int(row.v),:]\n",
    "                ucnt += 1\n",
    "            elif row.z == 'bandit':\n",
    "                # Pad the user embedding with zeros\n",
    "                #features = np.hstack((uemb,np.zeros(P)))\n",
    "                # One-hot encode the item in the last P columns\n",
    "                #features[self.K + int(row.a)] = 1.\n",
    "                aemb = np.zeros(P + 2)\n",
    "                aemb[int(row.a)] = 1.\n",
    "                aemb[-2] = self.item_popularities[int(row.a)]\n",
    "                dot = np.matmul(self.embeddings[int(row.a),:],uemb/ucnt)\n",
    "                aemb[-1] = dot\n",
    "                features = np.kron(uemb/ucnt, aemb)\n",
    "                X.append(features)\n",
    "                y.append(row.c)\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "        \n",
    "        # Train Logistic Regression model\n",
    "        self.model = LogisticRegression(solver = 'liblinear',\n",
    "                                        #C = .25,\n",
    "                                        max_iter = 200).fit(X,y)\n",
    "    \n",
    "    def observe(self, observation):\n",
    "        for session in observation.sessions():\n",
    "            self.user_embedding += self.embeddings[session['v'],:]\n",
    "            self.history_length += 1\n",
    "\n",
    "    def act(self, observation, reward, done):\n",
    "        \"\"\"Act method returns an Action based on current observation and past history\"\"\"\n",
    "        self.observe(observation)\n",
    "\n",
    "        # Generate a prediction for every possible action\n",
    "        X = []\n",
    "        for a in range(self.embeddings.shape[0]):\n",
    "            # Pad the user embedding with zeros\n",
    "            #features = np.hstack((self.user_embedding,np.zeros(self.embeddings.shape[0])))\n",
    "            # One-hot encode the item in the last P columns\n",
    "            #features[self.K + a] = 1.\n",
    "            aemb = np.zeros(self.embeddings.shape[0] + 2)\n",
    "            aemb[int(a)] = 1.\n",
    "            aemb[-2] = self.item_popularities[int(a)]\n",
    "            dot = np.matmul(self.embeddings[int(a),:],(self.user_embedding/self.history_length))\n",
    "            aemb[-1] = dot\n",
    "            features = np.kron((self.user_embedding/self.history_length), aemb)\n",
    "            X.append(features)\n",
    "        prob = self.model.predict_log_proba(np.asarray(X))[:,1]\n",
    "        prob = np.exp(prob-logsumexp(prob))\n",
    "        \n",
    "        if self.greedy:\n",
    "            a = np.argmax(prob)\n",
    "            prob = np.zeros(prob.shape)\n",
    "            prob[a] = 1.\n",
    "        \n",
    "        # Sample action according to probability distribution\n",
    "        action = self.rng.choice(self.config.num_products, p = prob)\n",
    "        return {\n",
    "            **super().act(observation, reward, done),\n",
    "            **{\n",
    "                'a': action,\n",
    "                'ps': prob[action],\n",
    "                'ps-a': prob,\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def reset(self):\n",
    "        self.user_embedding = np.zeros(self.K)\n",
    "        self.history_length = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "organic_counter_agent = OrganicUserEventCounterAgent(Configuration({\n",
    "            **organic_user_count_args,\n",
    "            **env_1_args,\n",
    "            'select_randomly': True,\n",
    "        }))\n",
    "\n",
    "random_args['num_products'] = P\n",
    "agent_rand = RandomAgent(Configuration({**env_1_args, **random_args,}))\n",
    "\n",
    "SVDLR = SVDLogRegAgent(Configuration(env_1_args), reco_log, U, P, 8, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A/B-Test Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate our new model by simulating an A/B-test against two baselines: the random agent and the popularity based agent.\n",
    "As we have seen before, although the popularity baseline is naive and simple, it is not always that trivial to beat in a first try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.025</th>\n",
       "      <th>0.500</th>\n",
       "      <th>0.975</th>\n",
       "      <th>Agent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009709</td>\n",
       "      <td>0.010016</td>\n",
       "      <td>0.010330</td>\n",
       "      <td>Random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.012128</td>\n",
       "      <td>0.012471</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>Popularity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009032</td>\n",
       "      <td>0.009328</td>\n",
       "      <td>0.009631</td>\n",
       "      <td>SVD-LR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0.025     0.500     0.975       Agent\n",
       "0  0.009709  0.010016  0.010330      Random\n",
       "1  0.012128  0.012471  0.012821  Popularity\n",
       "2  0.009032  0.009328  0.009631      SVD-LR"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_AB = verify_agents(env, U, {' Random': agent_rand, 'Popularity': organic_counter_agent, 'SVD-LR': SVDLR})\n",
    "result_AB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x123c95748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plot_verify_agents(result_AB)\n",
    "plt.ylabel('CTR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, we see a 14% improvement in click-through rate when comparing the popularity baseline with our new SVD-LR model.\n",
    "This difference might seem small, but you can imagine that a 14% increase in a million-dollar business has quite a big impact.\n",
    "\n",
    "There are many different ways of improving upon this model, we provide some straightforward ideas:\n",
    "- The embeddings currently used by the model are based on the eigen-decomposition of the co-count matrix. This approach implicitly assumes that zeroes in the matrix represent no correlation. However, this assumption often does not hold in the case of implicit-feedback datasets. More advanced matrix factorisation techniques such as WRMF, or pairwise learning procedures such as BPR might be used to further improve on the quality of the used embeddings.\n",
    "- Similar in spirit to the first suggestion, more advanced models such as recurrent neural networks (RNNs) can better capture the sequential nature of the relationships among items and users. Many embedding techniques that are often used in natural language processing (e.g. BERT) can be adapted to provide meaningful latent representations in the RecSys field as well.\n",
    "- More advanced classification techniques than Logistic Regression can be used to predict whether a user would or would not click on a given recommendation.\n",
    "- The training data we used in this model was generated under a fully randomised logging policy, with the result that we do not have to bother about missing-not-at-random (MNAR) data. However, in real world systems, this will seldom be the case. Many so-called Batch-Learning from Bandit-Feedback (BLBF) algorithms have been proposed in recent years, that focus on exploiting propensity estimates to effectively tackle the counterfactual nature of this setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
