
We need to complete three notebooks:


Bandit Feedback - evaluate organic model with bandit signal.ipynb
- Mostly done...  just explanation
- Reorder plots, start with a random logging policy, simulating an A/B test, doing offline evaluation on those logs, adding IPS,...
- Include Recall@k as a metric


Bandit Feedback - Likelihood based models.ipynb
- pull in  relevant stuff from Likelihood notebooks
- Ask Dmytro about numbers of features
- error bars on click through rates (Included)
- best of organic ( Included as GreedySingleActionAgent)
- best of bandit ( Included as GreedySingleActionAgent)
- Include comparison of greedy organic and greedy bandit agents with enough users such that confidence intervals no longer overlap
- reco with no cross
- personalised reco with cross

Specific actions:

1. around cell 31 put error bars on the plot
2. do a scatter plot with error bars of popularity vs click through rate (non personalised)
3. do a non-personalised bandit model.  Note that this really should be trained on random policy.
4. do a non-personalised organic model.  This already exists.. think about the best way to do this one..






Bandit Feedback - IPS based models.ipynb
- Nothing done yet.. write from scratch..
- Before we start what conclusion do we expect?  Contextul bandit wins?  Really?


Why does organic best of do well?
It seems the dot of the embedding with itself causes the popularity to vary..  controlling this may be useful or important, but not trivial.


